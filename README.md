# My Machine Learning Notes

## Pretrained Models
|Model description|Code|Paper
|---|---|---|
|BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding|<a href="https://github.com/google-research/bert">code</a>|<a href="https://arxiv.org/abs/1810.04805">paper</a>|
|Flair Embeddings|<a href="https://github.com/zalandoresearch/flair">code</a>|<a href="https://drive.google.com/file/d/17yVpFA7MmXaQFTe-HDpZuqw9fJlmzg56/view?usp=sharing">paper</a>|
|Generative Pre-Training (GPT-2)|<a href="https://github.com/openai/gpt-2">code</a>|<a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">paper</a>|
|ELMo: Deep contextualized word representations|<a href="https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md">code</a>|<a href="http://www.aclweb.org/anthology/N18-1202">paper</a>|
|Universal Sentence Encoder|<a href="https://tfhub.dev/google/universal-sentence-encoder/2">code</a>|<a href="https://arxiv.org/abs/1803.11175">paper</a>|
|InferSent sentence embeddings|<a href="https://github.com/facebookresearch/InferSent">code</a>|<a href="https://arxiv.org/abs/1705.02364">paper</a>|
<!--
|Placeholder|<a href="">code</a>|<a href="">paper</a>|
-->

## Classifiers
|Model description|Code|Paper
|---|---|---|
|Convolutional Neural Networks for Sentence Classification|<a href="https://github.com/yoonkim/CNN_sentence">code</a>|<a href="http://arxiv.org/abs/1408.5882">paper</a>|

