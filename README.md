# My Machine Learning Notes

## Pretrained Models
|Model description|Code|Paper
|---|---|---|
|BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding|<a href="https://github.com/google-research/bert">code</a>|<a href="https://arxiv.org/abs/1810.04805">paper</a>|
|Flair Embeddings|<a href="https://github.com/zalandoresearch/flair">code</a>|<a href="https://drive.google.com/file/d/17yVpFA7MmXaQFTe-HDpZuqw9fJlmzg56/view?usp=sharing">paper</a>|
